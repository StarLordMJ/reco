{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final List of Top 5 Places:\n",
      "['Dehiwala Zoological Gardens', 'Udawatta Kele Sanctuary', 'Nelum Pokuna Theatre', 'Nelung Arts Centre', 'Ridiyagama Safari Park']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "df0 = pd.read_csv('places_v7.csv')\n",
    "df1 = pd.read_csv('places_v8.csv')\n",
    "\n",
    "# Ensure necessary columns exist\n",
    "required_columns = ['categories', 'name', 'rating', 'user_ratings_total', 'positive_words', 'negative_words']\n",
    "for df in [df0, df1]:\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in the CSV file.\")\n",
    "\n",
    "# Create X and y for both datasets\n",
    "X0 = df0['categories']\n",
    "y0 = df0['name']\n",
    "\n",
    "X1 = df1['categories']\n",
    "y1 = df1['name']\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer0 = TfidfVectorizer()\n",
    "tfidf_vectorizer1 = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the input data\n",
    "X0_tfidf = tfidf_vectorizer0.fit_transform(X0)\n",
    "X1_tfidf = tfidf_vectorizer1.fit_transform(X1)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier0 = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "knn_classifier1 = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn_classifier0.fit(X0_tfidf, y0)\n",
    "knn_classifier1.fit(X1_tfidf, y1)\n",
    "\n",
    "# Function to calculate composite score\n",
    "def calculate_score(row):\n",
    "    rating = row['rating']\n",
    "    rating_count = row['user_ratings_total']\n",
    "    positive_count = row['positive_words']\n",
    "    negative_count = row['negative_words']\n",
    "    \n",
    "    # Weighted sum of factors (adjust these weights as needed)\n",
    "    score = (\n",
    "        0.2 * rating +\n",
    "        0.2 * np.log1p(rating_count) +  # log to dampen the effect of very high counts\n",
    "        0.5 * (positive_count / (positive_count + negative_count + 1)) +  # sentiment ratio\n",
    "        0.1 * np.log1p(positive_count + negative_count)  # total review length\n",
    "    )\n",
    "    return score\n",
    "\n",
    "# Calculate scores for all places in both datasets\n",
    "df0['score'] = df0.apply(calculate_score, axis=1)\n",
    "df1['score'] = df1.apply(calculate_score, axis=1)\n",
    "\n",
    "# Normalize scores\n",
    "scaler0 = MinMaxScaler()\n",
    "scaler1 = MinMaxScaler()\n",
    "df0['normalized_score'] = scaler0.fit_transform(df0[['score']])\n",
    "df1['normalized_score'] = scaler1.fit_transform(df1[['score']])\n",
    "\n",
    "# Define input categories\n",
    "input_categories = \"wildlife, theater, safaris\"\n",
    "\n",
    "# Split input categories by comma and strip any extra spaces\n",
    "category_list = [category.strip() for category in input_categories.split(',')]\n",
    "\n",
    "# Function to get predictions for a single category, verify them, and rank by score\n",
    "def get_verified_top_2_predictions(category, df, classifier, tfidf_vectorizer):\n",
    "    # Transform the input category using the same TF-IDF vectorizer\n",
    "    category_tfidf = tfidf_vectorizer.transform([category])\n",
    "\n",
    "    # Get the top 10 predictions for the dataset\n",
    "    top_10_predictions = classifier.kneighbors(category_tfidf, n_neighbors=10, return_distance=False)[0]\n",
    "\n",
    "    # Get predicted place names and verify their actual categories\n",
    "    verified_places = []\n",
    "    for prediction in top_10_predictions:\n",
    "        place_row = df.iloc[prediction]\n",
    "        actual_category = place_row['categories']\n",
    "        \n",
    "        # Verify if the predicted place's category matches the input category\n",
    "        if category.lower() in actual_category.lower():\n",
    "            verified_places.append(place_row)\n",
    "    \n",
    "    # Convert to DataFrame and sort by normalized score\n",
    "    if len(verified_places) > 0:\n",
    "        verified_df = pd.DataFrame(verified_places)\n",
    "        verified_df_sorted = verified_df.sort_values('normalized_score', ascending=False).head(2)\n",
    "        return verified_df_sorted[['name', 'rating', 'user_ratings_total', 'normalized_score']].to_dict('records')\n",
    "    \n",
    "    return []  # If no verified places found, return empty list\n",
    "\n",
    "# List to store the final top 6 places\n",
    "final_places_list = []\n",
    "\n",
    "# Iterate over each category and collect the top 2 places\n",
    "for category in category_list:\n",
    "    # Get verified places for df0 and df1\n",
    "    verified_places_0 = get_verified_top_2_predictions(category, df0, knn_classifier0, tfidf_vectorizer0)\n",
    "    verified_places_1 = get_verified_top_2_predictions(category, df1, knn_classifier1, tfidf_vectorizer1)\n",
    "    \n",
    "    # Combine results from both datasets and limit to 2 places\n",
    "    final_places = (verified_places_0 + verified_places_1)[:2]\n",
    "    \n",
    "    # Add the place names to the final list\n",
    "    for place in final_places:\n",
    "        final_places_list.append(place['name'])\n",
    "\n",
    "# Print the final list of 6 places\n",
    "print(\"Final List of Top 5 Places:\")\n",
    "print(final_places_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn_classifier0, 'knn_classifier0.pkl')\n",
    "joblib.dump(knn_classifier1, 'knn_classifier1.pkl')\n",
    "joblib.dump(tfidf_vectorizer0, 'tfidf_vectorizer0.pkl')\n",
    "joblib.dump(tfidf_vectorizer1, 'tfidf_vectorizer1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final List of Top 5 Places:\n",
      "['Dehiwala Zoological Gardens', 'Udawatta Kele Sanctuary', 'Nelum Pokuna Theatre', 'Nelung Arts Centre', 'Ridiyagama Safari Park']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the saved models and vectorizers\n",
    "knn_classifier0 = joblib.load('knn_classifier0.pkl')\n",
    "knn_classifier1 = joblib.load('knn_classifier1.pkl')\n",
    "tfidf_vectorizer0 = joblib.load('tfidf_vectorizer0.pkl')\n",
    "tfidf_vectorizer1 = joblib.load('tfidf_vectorizer1.pkl')\n",
    "\n",
    "# Reload the datasets (for reference and category validation)\n",
    "df0 = pd.read_csv('places_v7.csv')\n",
    "df1 = pd.read_csv('places_v8.csv')\n",
    "\n",
    "# Function to calculate composite score (reused for inference)\n",
    "def calculate_score(row):\n",
    "    rating = row['rating']\n",
    "    rating_count = row['user_ratings_total']\n",
    "    positive_count = row['positive_words']\n",
    "    negative_count = row['negative_words']\n",
    "    \n",
    "    # Weighted sum of factors (you can adjust these weights)\n",
    "    score = (\n",
    "        0.2 * rating +\n",
    "        0.2 * np.log1p(rating_count) +  # log to dampen the effect of very high counts\n",
    "        0.5 * (positive_count / (positive_count + negative_count + 1)) +  # sentiment ratio\n",
    "        0.1 * np.log1p(positive_count + negative_count)  # total review length\n",
    "    )\n",
    "    return score\n",
    "\n",
    "# Recalculate the scores (same as training)\n",
    "df0['score'] = df0.apply(calculate_score, axis=1)\n",
    "df1['score'] = df1.apply(calculate_score, axis=1)\n",
    "\n",
    "# Input categories for inference\n",
    "input_categories = \"wildlife, theater, safaris\"\n",
    "\n",
    "# Split input categories by comma and strip any extra spaces\n",
    "category_list = [category.strip() for category in input_categories.split(',')]\n",
    "\n",
    "# Function to get predictions for a single category, verify them, and rank by score\n",
    "def get_verified_top_2_predictions(category, df, classifier, tfidf_vectorizer):\n",
    "    # Transform the input category using the same TF-IDF vectorizer\n",
    "    category_tfidf = tfidf_vectorizer.transform([category])\n",
    "\n",
    "    # Get the top 10 predictions for the dataset\n",
    "    top_10_predictions = classifier.kneighbors(category_tfidf, n_neighbors=10, return_distance=False)[0]\n",
    "\n",
    "    # Get predicted place names and verify their actual categories\n",
    "    verified_places = []\n",
    "    for prediction in top_10_predictions:\n",
    "        place_row = df.iloc[prediction]\n",
    "        actual_category = place_row['categories']\n",
    "        \n",
    "        # Verify if the predicted place's category matches the input category\n",
    "        if category.lower() in actual_category.lower():\n",
    "            verified_places.append(place_row)\n",
    "    \n",
    "    # Convert to DataFrame and sort by normalized score\n",
    "    if len(verified_places) > 0:\n",
    "        verified_df = pd.DataFrame(verified_places)\n",
    "        verified_df_sorted = verified_df.sort_values('score', ascending=False).head(2)\n",
    "        return verified_df_sorted[['name', 'rating', 'user_ratings_total', 'score']].to_dict('records')\n",
    "    \n",
    "    return []  # If no verified places found, return empty list\n",
    "\n",
    "# List to store the final top 6 places\n",
    "final_places_list = []\n",
    "\n",
    "# Iterate over each category and collect the top 2 places\n",
    "for category in category_list:\n",
    "    # Get verified places for df0 and df1\n",
    "    verified_places_0 = get_verified_top_2_predictions(category, df0, knn_classifier0, tfidf_vectorizer0)\n",
    "    verified_places_1 = get_verified_top_2_predictions(category, df1, knn_classifier1, tfidf_vectorizer1)\n",
    "    \n",
    "    # Combine results from both datasets and limit to 2 places\n",
    "    final_places = (verified_places_0 + verified_places_1)[:2]\n",
    "    \n",
    "    # Add the place names to the final list\n",
    "    for place in final_places:\n",
    "        final_places_list.append(place['name'])\n",
    "\n",
    "# Print the final list of 6 places\n",
    "print(\"Final List of Top 5 Places:\")\n",
    "print(final_places_list[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
